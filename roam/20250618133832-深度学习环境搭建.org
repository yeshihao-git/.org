:PROPERTIES:
:ID:       6b621bcc-4bcb-45b2-a329-de610826fef7
:END:
#+title: deep learning环境搭建与实验
#+filetags: deep_learning

* 论文素材
** InfoNCE
信息噪声对比估计，对比学习中最核心、最常用的损失函数之一，核心思想是通过 区分正负样本 来优化 模型对数据特征的学习
三元组：锚点a、正样本p、副样本n1 n2 n3...；优化：锚点与正样本的相似度 > 与所有负样本的相似度
*** 图:InfoNCE公式 :ATTACH:
:PROPERTIES:
:ID:       9964171b-789b-4651-a79f-b7b9a91214c3
:END:
[[attachment:_20250915_204352screenshot.png]]
sim(x,y) 为 余弦相似度公式


* 思路
- 消息传播方式 => MGDN 替换模块 查看后续工作的论文（工具？）
- 3张图 => 改成2张：早期融合text和graph，再通过MGDN进行消息传播 => 可能可以减少计算量，提高text和graph模态的交互


* 实验
|   | 方法                | 类别           | 结果         | 来源   | 代码         |
|---+---------------------+----------------+--------------+--------+--------------|
| x | OSF                 | 多模态融合     | 普遍大幅降低 | 豆包ai |              |
| - | GMU                 | 门控多模态融合 | 普遍小幅降低 | [[https://blog.csdn.net/zly_Always_be/article/details/135634388#pytorch_31][CSDN]]   | [[id:f7009f6d-ea96-49ad-97a3-65cb23404585][GMU]]          |
| + | SMORE：去噪融合模块 | 频域去噪、融合 | 提升1个点    |        | [[id:a7eede37-3607-40fe-9d34-f6df4dd2ccde][频域去噪融合]] |
| x | MGCN                |                | 降低         | [[https://github.com/enoche/MMRec/tree/master][github]] |              |

** MIG_GT 张量形状
融合前：   emb_h、t_h、v_h              形状 [26495, 64]
融合后：   combined_h                   形状 [26495, 64]
MLP处理前：item_t_feat、item_v_feat     形状 [7050，384]

** MIG_GT 实验
论文
| 0.0665 | 0.1021 | 0.0361 | 0.0452 |
复现
| 0.0654 | 0.1015 |  0.0356 |  0.0448 | baby               |
| 0.0668 | 0.1031 |  0.0365 |  0.0458 | baby(频域去噪)     |
| 0.0014 | 0.0016 |  0.0009 |  0.0010 |                    |
|--------+--------+---------+---------+--------------------|
| 0.0740 | 0.1116 |  0.0406 |  0.0503 | sports             |
| 0.0753 | 0.1125 |  0.0411 |  0.0508 | sports(频域去噪)   |
| 0.0013 | 0.0009 |  0.0005 |  0.0005 |                    |
|--------+--------+---------+---------+--------------------|
| 0.0634 | 0.0925 |  0.0353 |  0.0427 | clothing           |
| 0.0639 | 0.0932 |  0.0348 |  0.0421 | clothing(频域去噪) |
| 0.0005 | 0.0007 | -0.0005 | -0.0004 |                    |





* trick
- 归一化 :: *加速训练* ，缓解 *梯度消失/爆炸* 问题
  数据分布 是数据在不同取值上的规律，可以通过均值和方差决定，神经网络对于数据分布很敏感，如果输入数据的范围差距过大，则会出现梯度不稳定，因此需要将数据归一化为 均值为0、方差为1
  - Dropout :: 随机丢弃部分神经元，防止 *过拟合* ，增强模型的泛化能力
- 残差连接 :: 极端情况下，即使增加的层什么都没有学习到，深层网络的性能也至少和浅层网络一样
- 激活函数 :: 引入非线性，使神经网络可以 *拟合复杂函数* （否则多层线性变换等价于单层）


* 复现
** MIG-GT [[https://github.com/CrawlScript/MIG-GT][github]]
1. conda创建环境python3.8
2. torch安装：torch==1.12.1+cu113；见 [[id:cfe89b94-ace5-4816-896f-a1ffce8d10c5][pip安装torch(带cuda)]]
   #+begin_src bash
   pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113
   #+end_src
3. dgl安装：dgl-cuda11.3-0.9.1post1-py38_0.tar.bz2；见 [[id:6c6faca5-847e-4b1a-a882-4246f293b573][pip安装dgl]]
4. torch-scatter安装；见 [[id:e00f1993-5152-4a4c-866c-f0fe91761cb8][pip安装torch-scatter]]
5. 按照 Requirements 需求安装剩余的内容；见 [[id:5fb308e4-2d7c-43ba-8c39-07cc94d02c2d][pip安装faiss]] [[id:8a2869e2-dc0b-40e9-acf5-4f80fb954de8][pip安装yaml]]
   #+begin_src bash
   pip install torchmetrics==0.11.4 ogb==1.3.5 shortuuid==1.0.11 pandas==1.3.5 numpy==1.21.6 tqdm==4.64.1 networkx faiss-gpu lmdb pyyaml
   #+end_src
6. 运行
   #+begin_src bash
   python main.py --gpu 0 --seed 1 --dataset baby --result_dir results --method mig_gt
   #+end_src

** FREEDOM [[https://github.com/enoche/FREEDOM][参考]]
1. conda创建环境python3.8
2. torch安装：torch==1.12.1+cu113
